
<html>
    <!-- FILL IN EVERYTHING SURROUNDED BY CURLY BRACES UNLESS OTHERWISE SPECIFIED -->
    <head>
        <link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css">
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Assignment 5 &laquo; Machine Learning&raquo;</title>
    </head>
    
    <body>
    
    <div class="row" style="margin-bottom: 30px;">
            <div class="col-md-2"></div>
            <div class="col-md-8">
                <div class="page-header center">
                    <h1>Assignment 5 <small>&laquo; Machine Learning&raquo;</small></h1>
                </div>
    
                <h3>Due: 11:59PM, July 13, 2021 ET</h3>
    
                <h2>Overview</h2>
                    <img src="unsupervised_meme.jpg" alt="unsupervised meme" style="width:auto; height: 400px">
                    <p>Boomers have decided to explore machine learning because they are VERY tech-savvy and willing to learn. In this assignment you will help them accomplish various tasks and stay one step ahead of their mortal enemies, the bag ban and participation trophies. The goal of this assignment is to introduce basic machine learning concepts and provide a foundation for how to cluster data.</p>
                
                <br><hr><br>
    
                <h2>Assignment</h2>
                <p>In this assignment we will begin to explore the power data has in informing machine learning decisions. These boomers require an effective way to manipulate data attributes. Numpy is a python package that will help accomplish this. You will use the knowledge gained to help these boomers implement a K-means clustering algorithm. You will run this algorithm on two different datasets and implement sklearn's clustering algorithm on both data sets. Finally, you will make an elbow curve plot to discover the optimal number of centroids.</p>
                <br>
                <h3>Getting the Stencil</h3>
                        <p>
                          You can click <a href="https://classroom.github.com/a/Or9gOnRa">here</a> to get the stencil code for this homework. Reference <a href="https://docs.google.com/document/d/1v3IQrC_0pFxsRBXsvCEzKBDAmYjzuSJCvXhkg8ewDn0/edit">this guide</a> for more information about Github and Github Classroom.
                        </p>
                        
                        <p>
                          The data is located in the data folder. To ensure compatibility with the autograder, you should not modify the stencil unless instructed otherwise. For this assignment, please write your solutions in the respective <code>.py</code> files. Failing to do so may hinder with the autograder and result in a low grade.
                        </p>
                        <p>As per usual, don't forget to activate the course's virtual environment when running the files in this assignment! :)</p>
                <br>
                <h3>FAQ - Plotting Graphs</h3>
                <p>In this assignment, you will be using the Python package <code>matplotlib</code> to plot graphs and images. For most machines, the matplotlib package that we installed in HW0 (that is available in the virtual environment) would work fine. However, some machines that have an updated version of their operating system might run into a <code>Segmentation fault</code>. In this case, try to type these two commands in to your terminal:</p>
                <pre>
    pip uninstall matplotlib
    pip install matplotlib</pre>
                <p>These two command lines will first uninstall your existing version of the <code>matplotlib</code> package, and then install the latest version of <code>matplotlib</code> to your computer. Don't forget to do these two steps with your virtual environment activated!</p>
                <p>If you run into any problems graphing your images or plots, feel free to come to TA Hours to get your issue resolved!</p>
                        <br><hr><br>
                <h2>Part 1: K-means Algorithm</h2>
                <h4>40 points</h4>
                    <p>K-means clustering is an algorithm designed to sort data into groups based on similarity. To determine the groups, K-means repeatedly performs an update step, detailed by the following pseudocode:</p>
                    <pre>
    For each data_point:
        Determine closest centroid
    For each centroid:
        Determine centroid location as average of data_points which are closest to that centroid  </pre>
                <p>To determine the closest centroid, you will be using a variation of <code>Euclidean distance: distance = ∑<sub>i</sub>(a<sub>i</sub> - b<sub>i</sub>)^2</code> where <i>a<sub>i</sub></i>, <i>b<sub>i</sub></i> are the different features of data_point <i>a</i> and data_point <i>b</i> (hint: refer to the numpy way to calculate euclidean distance). To determine the centroids' new locations, you average together the data points for which that was the closest centroid. This means that a centroid is defined by its own feature set.</p>
                <p>The real power of K-means comes from measuring distance with meaningful features of a dataset. For example, some meaningful features of a song might include its acousticness, danceability, and tempo. By applying K-means to a collection of songs, where the distance function between songs is based on these features, our resulting clusters will divide our songs into genres.</p>
                <img src="kmeans.png" alt="kmeans" style="width:800px; height: 400px">
                <br>
                <h4>Part 1.1: K-means Class</h4>
                <p>In this assignment you will be implementing your own version of K-means. We have provided you with stencil code located in <code>kmeans.py</code> and specific instructions about the methods you will need to fill in. Your first step is to fill in the outlined methods which will later be used on two data sets to test your code.</p>
                <p>
                    <b>Note: </b>Please follow the input output specifications for each class member functions in the <code>Kmeans</code> class.
                </p>
                <br>
                <h4>Part 1.2: Image Compression with K-Means</h4>
                <p>In this part <code>img_compression.py</code> takes in an image and breaks it up in RGB pixel values. It then uses these three values as features in your K-means algorithm to cluster by color similarity to compress the provided image. You do not need to change any code for this section, but run the file to see what clusters it returns.</p>
    
                <p>For this problem, use the <code>tiger.jpg</code> image as the input to your program. To run the file, execute the following command:</p>
    
                <pre>$ python3 img_compression.py [-d PATH/TO/tiger.jpg]</pre>
    
                <p>where <code>PATH/TO/tiger.jpg</code> is the path to the image file. By default, without the <code>-d</code> flag, the data file path is <code>../data/ml/tiger.jpg</code>. Successfully running the script will create files named <code>centroids.txt</code> and <code>tiger.jpg</code> in a new folder named <code>output</code>, which will contain the saved clusters and the compressed image.</p>
    
                <p><b>Note: </b>This part should take no longer than 30 minutes to run for 50 iters if your k-means is implemented correctly.
                We have written a function <code>img_distance</code> which calculates an element-wise (pixel-by-pixel) difference. We won't be grading this difference, but to check if your k-means is implemented correctly, note that with <code>K=16</code>
                and <code>max_iters = 50</code>, our distance is around <b>62</b>. This is purely for your reference.
                </p>
                
                <br><hr><br>
    
                <h2>Part 2: Song Clustering</h2>
                <h4>30 points</h4>
                <br>
                <h4>Part 2.1: Task Overview</h4>
                <p>
                    Once you have filled out <code>kmeans.py</code> you can proceed to use your k-means class on clustering
                    songs by latent audio features. This data can be found in <code>spotify.csv</code> in the data directory
                    and consists of 600 top Spotify songs from 2010-2019.
    
                </p>
                <p>
                    We have included <kbd>TODO</kbd> comments in <code>song_clustering.py</code> to help with completing
                    this part of the assignment. You should only
                    have to edit functions in this file, and please note the input/output specifications of the functions,
                    as well as the expected output behavior (<kbd>Part 2.6</kbd> below).
    
                    You will have to complete the following parts in the <code>cluster_songs</code> function, completing
                    additional functions as specified.
                </p>
                <br>
                <h4>Part 2.2: Data Preprocessing</h4>
                <p>
                    The original dataset consists of 13 features
                    (Beats per Minute, Danceability, Acousticness, etc), but we will be using a subset of the features for
                    the purposes of this assignment. We have written preprocessing code to extract three features from this
                    dataset, specifically "acousticness", "speechiness", and "liveness". Your task is to use these three
                    features to cluster the songs into clusters of similar songs.
                </p>
                <p>
                    Our preprocessing code removes outliers from the dataset. Please fill out the <code>min_max_scale</code>
                    function. Performing MinMax scaling prevents different scales of the data feature columns from
                    influencing distance calculations. Each column of the dataset should be standardized by the formula
                    found in the function's docstring.
                </p>
                <br>
                <h4>Part 2.3: Visualizing the Data</h4>
                <p>
                    This dataset can be visualized in 3D, and we have written a function <code>visualize_songs_clusters</code>
                    to do so. You will use this same function to visualize the raw data as well as the cluster centroids
                    for both your custom <code>kmean</code> object and the library <code>sklearn.cluster.KMeans object</code>
                    (more details in <kbd>Part 2.5</kbd>).
                </p>
                <p>
                    By passing in optional <code>centroids</code> and <code>centroid_indices</code> arguments, you can visualize
                    each datapoint and which cluster it belongs to. Please note the optional <code>is_lib_kmean</code> argument
                    which should be set to <code>True</code> when visualizing results in <kbd>Part 2.5</kbd>.
                </p>
                <br>
                <h4>Part 2.4: Elbow Curve</h4>
                <p>
                    Once you have written your k-means clustering algorithm, you might be wondering how many clusters should
                    you use for a dataset. The number of clusters is called a hyperparameter of the machine learning
                    algorithm and hyper parameter tuning is an important part of machine learning. One method to computing
                    the number of clusters is plotting out the number of clusters and the <i>inertia</i> of the cluster
                    assignments.
                </p>
                <p>
                    <i>Inertia</i> is defined as the sum of the squared distances between each data point and the
                    centroid of its assigned cluster.
                </p>
                <p>
                    As more clusters are added, inertia decreases. However, there are diminishing returns to this. The ideal
                    number of clusters is a judgement call by looking at the “elbow point” of this graph where adding the
                    next cluster does not significantly reduce inertia.
                </p>
                <p>
                    In <code>song_clustering.py</code> we have provided an <code>elbow_point_plot()</code> function that takes
                    in an np array of the number of clusters (x-axis) and an np array of inertia values (y-axis). The output
                    graph will be saved to the <kbd>output</kbd> directory as <code>elbow_plot.png</code>.
                    Analyze the graph and determine the ideal number of clusters. Below is an <b>example</b> of an
                    elbow point curve of a <b>different</b> dataset.
                    <br/>
                    <img src="elbow.png" alt="kmeans" style="width:auto; height: 300px">
                </p>
                <br>
                <h4>Part 2.5: <code>scikit-learn</code></h4>
                <p>
                    Programming machine learning algorithms is a good way to internalize concepts and get a better understanding
                    for how they work. However, in practice, machine learning libraries are often used to speed up data analysis.
                    For this part of the assignment, we will perform K-means clustering using <code>scikit-learn</code>, a popular machine learning library.
                    Click <a href="https://scikit-learn.org/stable/documentation.html"> here </a> to learn more about <code>scikit-learn</code>
                    and <a href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html">here</a>
                    for the documentation on its <code>KMeans</code> class
                </p>
    
                <p>
                    Fill in the <code>sk_learn_cluster</code> function using <code>sklearn.cluster.KMeans</code> object.
                    The function takes in <code>X</code> - the dataset of Spotify data, and
                    <code>K</code> - the number of clusters and should output an np array where every index contains the
                    cluster of the corresponding vector as well as the coordinates of the cluster centers.
                    <i>Hint: This can be done in just 3 lines of code!</i>
                </p>
                <p>
                    You should also visualize your cluster results with the same <code>visualize_songs_clusters</code> used
                    previously, except this time with <code>is_lib_kmean=True</code>.
                </p>
                <br>
                <h4>Part 2.6 Run Specifications</h4>
                <p>
                To run the file, execute the following command:
    
                <pre>$ python3 song_clustering.py [-d PATH/TO/spotify.csv]</pre>
                By default, without the <code>-d</code> flag, the data file path is <code>../data/ml/spotify.csv</code>.
                </p>
    
                <p>
                Calling <code>visualize_songs_clusters</code> will save the generated plot to the <code>output</code> folder.
                You should call this function <b>3</b> times to generate plots of the <b>raw data</b>, <b>clustered data
                with your <code>kmeans</code> object</b>, and <b>clustered data with the <code>sklearn.cluster.KMeans</code>
                object</b>.
                </p>
    
                <p>
                    The cluster centers and centroid indices for each datapoint for both your model and the <code>scikit-learn</code> model
                    will be exported to a file named <code>song_clusters.json</code>. Note you must return these 4 items
                    from your <code>cluster_songs</code> function.
                </p>
    
                <p>
                Successfully running the script will create the following files in your <code>output</code> directory <i>based on
                running solely <code>song_clustering.py</code></i>:
                <ol>
                    <li><code>data_raw.png</code></li>
                    <li><code>data_clusters.png</code></li>
                    <li><code>data_clusters_sklearn.png</code></li>
                    <li><code>elbow_plot.png</code></li>
                    <li><code>song_clusters.json</code></li>
                </ol>
                </p>
    
    
                Make sure that when we run your code, it plots the <b>4</b> graphs outlined above.
                </p>
    
                <b>Important:</b> Please be sure to follow the inputs and outputs as specified in the stencil code.
                Be careful in <i>not</i> changing the portions of the stencil we specify.
                </p>
    
                <br><hr><br>
    
                <h2>Part 3: Written Questions</h2>
                <h3>30 points</h3>
                <p>Answer the following questions in <code>writeup.md</code>.<p>
                <ol>
                    <li><p>Explain your K-Means algorithm. What are the parts of your algorithm, and how do they work together to divide your samples into different clusters?</p>
                    </li>
                    <li><p>What is K-Means used in the context of image compression? That is:
                        <ul>
                            <li>What is each data point that is being divided into clusters? what does each cluster represent?</li>
                            <li>How does changing the number of clusters impact the result of the song dataset and the image compression dataset?</li>
                        </ul></p>
                    </li>
                    <li><p>What is the difference between supervised classification, supervised regression, and unsupervised learning? Give an example of an algorithm under each, specifying the type of data that the algorithm takes in and the goal of the algorithm, and an explanation for why they are a supervised classification/supervised regression/unsupervised algorithm.</p></li>
                    <h3>Fair K-Means</h3>
                    <p>The growing research field of machine learning fairness attempts to prevent bias in ML systems. Research efforts to computationally define fairness have given rise to a debate about what it means for a machine learning model to be “fair.” Fair K-Means is one example of an attempt to define and improve fairness in clustering problems. The goal of the following questions is to demonstrate how you could incorporate machine learning fairness in your K-means implementation and explore the limitations of this approach to fairness.
                    </p>
                    <p style="font-style: italic;">Your responses should be thoughtful, provide justification for your claims, and be concise but complete. See the <a href="https://docs.google.com/document/d/1hXGxoW8DQzIBh1yW2989fZhOIBgJ4w8BMN6lXjbnY-U/edit">response guide</a> for more guidance.</p>
                    <h4> Questions </h4>
                    <p>Read <a href="https://montrealethics.ai/research-summary-fairness-in-clustering-with-multiple-sensitive-attributes/">this summary</a> of a research paper proposing a clustering algorithm called Fair K-Means. If you’re interested, the full paper is linked <a href="https://arxiv.org/pdf/1910.05113.pdf">here</a>. 
                    </p>
                    <li><p>Give an overview of how you would modify your Kmeans class to implement Fair K-Means in <code>kmeans.py</code>. Describe any methods you would add and where you would call them. You don’t need to understand the mathematical details of the Fair K-Means algorithm to have a general idea of the key changes necessary to modify your solution.</p>
                    </li>
                    <li><p>How does the Fair K-means algorithm define fairness? Describe a situation or context where this definition of fairness might not be appropriate, or match your own perception of fairness. </p>
                    </li>
                    <li><p>Are there any situations in which even a perfectly fair ML system might still cause or even exacerbate harm? Are there other metrics or areas of social impact you might consider? Justify your opinion. </p>
                    </li>
                </ol>
                <h4>
                    Additional Information
                </h4>
                <ul>
                    <li> If you’re interested in understanding and mitigating common "traps" that fair-ML work can fall into, check out the paper <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3265913">"Fairness and Abstraction in Sociotechnical Systems."</a>
                    </li>
                    <li> If you’re interested in examining other concerns of social impact beyond fairness, check out <a href="https://www.technologyreview.com/2021/03/11/1020600/facebook-responsible-ai-misinformation/">this article</a> describing challenges to the fairness paradigm at Facebook.
                    </li>
                </ul>
    
                <br><hr><br>
    
                <h2>Handing In</h2><br>
                    <p>After finishing the assignment (and any assignment in the future), run <code>python3 zip_assignment.py</code> in the command line from your assignment directory, and fix any issues brought up by the script. </p>
                    <p>After the script has been run successfully, you should find the file <code>ml-submission-1951A.zip</code> in your assignment directory. Please submit this zip file on Gradescope under the respective assignment.
                      (If you have not signed up for Gradescope already, please refer to this <a href="https://docs.google.com/document/d/1X_SAAVeGNcZW9HbaM-ev8h9RrhLWtlTSYfMkE8jWVdQ/edit#heading=h.lnyy1apmgq9k">guide</a>.)
                    </p>
                    
                <br><hr><br>
                <h2>Credits</h2>
                    <p>
                        Made in Spring 2020 by Karlly, Huayu, and Arvind, adapted from the previous TA staff for CS1951A. Revised for Spring 2021 by JP & Daniela. Updated in Summer 2021 by Nam and Evan.
    
                        Spotify dataset sourced from <a href="https://www.kaggle.com/leonardopena/top-spotify-songs-from-20102019-by-year">Kaggle</a>.
                    </p>
            </div>
    
            <div class="col-md-2"></div>
            <br><br>
    </div>
    
    </body>
    </html>    
